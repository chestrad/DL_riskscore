{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44116abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "import random\n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b31ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d59ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=\"bone\" #Prediction target\n",
    "date=20230302     \n",
    "Efficients=[5]  #EfficientNetB5\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b055021",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# loading lists of png files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb399fdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.list_files('/home/hk/Research/CXRage/pngbone/train/*.png', shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f00d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count1 = len(train_ds)\n",
    "train_ds = train_ds.shuffle(image_count1, reshuffle_each_iteration=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae7d272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.list_files('/home/hk/Research/CXRage/pngbone/val/*.png', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098ac70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count2 = len(val_ds)\n",
    "val_ds = val_ds.shuffle(image_count2, reshuffle_each_iteration=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707ed57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.list_files('/home/hk/Research/CXRage/pngbone/test/*.png', shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84706b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count3 = len(test_ds)\n",
    "test_ds = test_ds.shuffle(image_count3, reshuffle_each_iteration=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b291c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training set cases: 38166\n",
      "Number of validation set cases: 4710\n",
      "Number of test set cases: 4794\n"
     ]
    }
   ],
   "source": [
    "print('Number of training set cases: %d'%(image_count1))\n",
    "print('Number of validation set cases: %d'%(image_count2))\n",
    "print('Number of test set cases: %d'%(image_count3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d1dce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/home/hk/Research/CXRage/result/%s_%d\"%(label, date))\n",
    "os.chdir(\"/home/hk/Research/CXRage/result/%s_%d\"%(label, date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cee2cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# tf dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5876b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename, imagesize, augment=False): \n",
    "    raw = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(raw, channels=3)\n",
    "    \n",
    "    image.set_shape([512, 512, 3])  \n",
    "    image = tf.image.resize(image, [imagesize, imagesize]) \n",
    "    \n",
    "    if augment:\n",
    "        image = tf.image.random_brightness(image, max_delta=25)\n",
    "        image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "        image = tf.clip_by_value(image, 0, 255)        \n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e65f539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filename):\n",
    "    label = tf.strings.split(filename, sep=\".\")[-2]\n",
    "    label = tf.strings.to_number(label, tf.float32)  \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29c36c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_augmentation = Sequential(\n",
    "    [tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=(-0.1, 0.1), fill_mode=\"constant\"),   \n",
    "     tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n",
    "     tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=(-0.05, 0.05), width_factor=(-0.05, 0.05), fill_mode=\"constant\"),\n",
    "     tf.keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.05, 0.05), fill_mode=\"constant\")\n",
    "    ],\n",
    "    name=\"img_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb8fd74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    if chosen==\"B2\":\n",
    "        ds = ds.cache() \n",
    "    ds = ds.shuffle(buffer_size=1000) \n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f8bc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92be95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(targetmodel, imagesize):\n",
    "    \n",
    "    inputs = layers.Input(shape=(imagesize, imagesize, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    model = targetmodel(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    droprate=0.3\n",
    "\n",
    "    x = layers.Dropout(droprate, name=\"dropout1\")(x)\n",
    "    x = layers.Dense(256, kernel_initializer='he_normal', activation=\"relu\")(x)   \n",
    "    \n",
    "    x = layers.Dropout(droprate, name=\"dropout2\")(x)\n",
    "    x = layers.Dense(128, kernel_initializer='he_normal', activation=\"relu\")(x)  \n",
    "    \n",
    "    x = layers.Dropout(droprate, name=\"dropout3\")(x)\n",
    "    x = layers.Dense(64, kernel_initializer='he_normal', activation=\"relu\")(x)  \n",
    "    \n",
    "    x = layers.Dropout(droprate, name=\"dropout4\")(x)\n",
    "    outputs = layers.Dense(1, kernel_initializer='zeros', bias_initializer='zeros', activation=\"sigmoid\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=cos_decay_ann),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b539776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_model(model):\n",
    "    for layer in model.layers:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ead6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in Efficients:    \n",
    "\n",
    "    path=\"/home/hk/Research/CXRage/result/%s_%d_EfficientNetB%d\"%(label, date, i)\n",
    "\n",
    "    paths=[path,\n",
    "           \"%s/transfer/best\"%(path),\n",
    "           \"%s/transfer/final\"%(path),           \n",
    "           \"%s/FFT/best\"%(path),\n",
    "           \"%s/FFT/final\"%(path)]    \n",
    "    \n",
    "    for savepath in paths:\n",
    "        if os.path.isdir(savepath)==True:\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(savepath)\n",
    "    \n",
    "    os.chdir(\"%s/transfer\"%(path))\n",
    "    \n",
    "    chosen=\"B%d\"%(i) \n",
    "    \n",
    "    if chosen==\"B0\":\n",
    "        imagesize=224\n",
    "    elif chosen==\"B1\":\n",
    "        imagesize=240\n",
    "    elif chosen==\"B2\":\n",
    "        imagesize=260\n",
    "    elif chosen==\"B3\":\n",
    "        imagesize=300\n",
    "    elif chosen==\"B4\":\n",
    "        imagesize=380\n",
    "    elif chosen==\"B5\":\n",
    "        imagesize=456\n",
    "    elif chosen==\"B6\":\n",
    "        imagesize=528\n",
    "    elif chosen==\"B7\":\n",
    "        imagesize=600            \n",
    "    \n",
    "    def process_path_train(file_path):\n",
    "        label = get_label(file_path) \n",
    "        img = load_image(file_path, imagesize, augment=True)\n",
    "        return img, label\n",
    "    \n",
    "    def process_path(file_path):\n",
    "        label = get_label(file_path) \n",
    "        img = load_image(file_path, imagesize)\n",
    "        return img, label    \n",
    "    \n",
    "    print(\"In training: EfficientNet%s\"%(chosen))\n",
    "    print(\"Input image size is: %d\"%(imagesize))\n",
    "    \n",
    "    train_ds1 = train_ds.map(process_path_train, num_parallel_calls=tf.data.AUTOTUNE)  \n",
    "    val_ds1 = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_ds1 = test_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    train_ds1 = configure_for_performance(train_ds1)\n",
    "    val_ds1 = configure_for_performance(val_ds1)\n",
    "    test_ds1 = configure_for_performance(test_ds1)    \n",
    "    \n",
    "    targetmodel = eval(\"EfficientNetB%d\"%(i))    \n",
    "    \n",
    "    cos_decay_ann = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=0.01, first_decay_steps=30, t_mul=2, m_mul=0.95, alpha=0.01)\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=40) \n",
    "    csv_logger = keras.callbacks.CSVLogger('./Model transfer log.csv', append=False, separator=';')\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"%s/transfer/best\"%(path), \n",
    "                                                   verbose=0, \n",
    "                                                   save_best_only=True, monitor='val_auc', mode='max')\n",
    "    \n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy() \n",
    "    \n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_model(targetmodel, imagesize) \n",
    "    hist = model.fit(train_ds1, epochs=epochs, validation_data=val_ds1,\n",
    "                     callbacks=[early_stopping, csv_logger, checkpointer],\n",
    "                     verbose=2)\n",
    "    \n",
    "    model.save(\"%s/transfer/final\"%(path))\n",
    "    model.save(\"%s/transfer/CXRage_transfer_final.h5\"%(path))\n",
    "    \n",
    "    hist1 = pd.DataFrame(hist.history)\n",
    "    hist1['epoch'] = hist.epoch\n",
    "    hist1.to_csv('history_transfer.csv', index=False, header=True)\n",
    "    \n",
    "    del hist\n",
    "    del hist1\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"Transfer learning done\")\n",
    "    \n",
    "    os.chdir(\"%s/FFT\"%(path))\n",
    "    \n",
    "    cos_decay_ann = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=0.001, first_decay_steps=30, t_mul=2, m_mul=0.95, alpha=0.01)    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=40) \n",
    "    csv_logger = keras.callbacks.CSVLogger('./Model FFT log.csv', append=False, separator=';')\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"%s/FFT/best\"%(path), \n",
    "                                                   verbose=0, \n",
    "                                                   save_best_only=True, monitor='val_auc', mode='max')\n",
    "    \n",
    "    with mirrored_strategy.scope(): \n",
    "        unfreeze_model(model) \n",
    "        model.compile(optimizer=keras.optimizers.SGD(learning_rate=cos_decay_ann),\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['AUC'])\n",
    "        \n",
    "    hist = model.fit(train_ds1, epochs=epochs, validation_data=val_ds1, \n",
    "                     callbacks=[early_stopping, csv_logger, checkpointer],\n",
    "                     verbose=2) \n",
    "    \n",
    "    model.save(\"%s/FFT/final\"%(path))\n",
    "    model.save(\"%s/FFT/CXRage_FFT_final.h5\"%(path))\n",
    "    \n",
    "    hist1 = pd.DataFrame(hist.history)\n",
    "    hist1['epoch'] = hist.epoch\n",
    "    hist1.to_csv('history_FFT.csv', index=False, header=True)     \n",
    " \n",
    "    del model\n",
    "    del hist\n",
    "    del hist1 \n",
    "    del train_ds1\n",
    "    del val_ds1\n",
    "    del test_ds1\n",
    "    del imagesize\n",
    "    del targetmodel\n",
    "    del chosen\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    gc.collect()\n",
    "    gc.collect()  \n",
    "    \n",
    "    print(\"Full fine-tuning done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
